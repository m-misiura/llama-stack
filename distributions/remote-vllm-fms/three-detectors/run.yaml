version: '2'
image_name: remote-vllm-fms-three-detectors
apis:
  - inference
  - safety
  - shields

providers:
  inference:
    - provider_id: vllm-inference
      provider_type: remote::vllm
      config:
        url: ${env.VLLM_URL}
        max_tokens: ${env.MAX_TOKENS:4096}
        api_token: ${env.VLLM_API_TOKEN}
        model_name: ${env.INFERENCE_MODEL}
  
  safety:
    - provider_id: fms-safety
      provider_type: remote::fms
      config:
        shields:
          regex:
            type: content
            base_url: ${env.FMS_REGEX_URL}
            confidence_threshold: 0.5
            detector_params:
              regex: ["email"]
            message_types: ["system"]
          hap:
            type: content
            base_url: ${env.FMS_HAP_URL}
            confidence_threshold: 0.5
            message_types: ["user", "system"]
          chat:
            type: chat
            base_url: ${env.FMS_CHAT_URL}
            confidence_threshold: 0.5
            detector_params:
              temperature: 0.0
              risk_name: "Star Wars"
              risk_definition: "The message contains references to Star Wars, especially Luke Skywalker."
            message_types: ["system", "completion"]

metadata_store:
  type: sqlite
  db_path: ${env.SQLITE_STORE_DIR:~/.llama/distributions/remote-vllm-fms/three-detectors}/registry.db

models:
  - model_id: "meta-llama/Llama-3.1-8B-Instruct"
    provider_id: vllm-inference
    name: "Llama 3.1 8B Instruct"
    description: "Llama language model for text generation"

server:
  port: 5001
  tls_certfile: null
  tls_keyfile: null