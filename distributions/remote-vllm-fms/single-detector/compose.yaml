services:
  llamastack:
    build:
      context: ../../..
      dockerfile: distributions/remote-vllm-fms/single-detector/Dockerfile
    ports:
      - "${LLAMA_STACK_PORT:-5001}:5001"
    env_file:
      - .env
    platform: ${DOCKER_DEFAULT_PLATFORM:-linux/amd64}
    volumes:
      - ~/.llama:/root/.llama
      - ./run.yaml:/root/llamastack-run-remote-vllm.yaml
    network_mode: ${NETWORK_MODE:-bridge}
    environment:
      # Remote VLLM Configuration
      - VLLM_URL=${VLLM_URL}
      - VLLM_API_TOKEN=${VLLM_API_TOKEN}
      - INFERENCE_MODEL=${INFERENCE_MODEL}
      - MAX_TOKENS=${MAX_TOKENS:-4096}
      # FMS Configuration
      - FMS_REGEX_URL=${FMS_REGEX_URL}
      # Storage Configuration
      - SQLITE_STORE_DIR=/root/.llama/distributions/remote-vllm-fms/single-detector
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3